---
title: "Project eda"
author: "Xueyan Hu"
date: "2023-02-22"
output: html_document
---

  
  
This Quarto file loads the cleaned data and does some exploring.

I'm only showing it the way where the code is included in the file. 
As described in the `processing_code` materials, I currently prefer the approach of having R code in a separate file and pulling it in.

But I already had this written and haven't yet re-done it that way. Feel free to redo and send a pull request on GitHub :)

Again, it is largely a matter of preference and what makes the most sense to decide if one wants to have code inside Quarto files, or as separate R files.
And sometimes, an R script with enough comments is good enough and one doesn't need a Quarto file.

Also note that while here I split cleaning and exploring, this is iterative. You saw that as part of the processing, we already had to explore the data somewhat to understand how to clean it. In general, as you explore, you'll find things that need cleaning. As you clean, you can explore more. Therefore, at times it might make more sense to combine the cleaning and exploring code parts into a single R or Quarto file. Or split things in any other logical way.

As part of the exploratory analysis, you should produce plots or tables or other summary quantities for the most interesting/important quantities in your data. Depending on the total number of variables in your dataset, explore all or some of the others. Figures produced here might be histograms or density plots, correlation plots, etc. Tables might summarize your data.

Start by exploring one variable at a time. Then continue by creating plots or tables of the outcome(s) of interest and the predictor/exposure/input variables you are most interested in. If your dataset is small, you can do that for all variables. 

Plots produced here can be scatterplots, boxplots, violinplots, etc. Tables can be simple 2x2 tables or larger ones.

# Setup

```{r}
#load needed packages. make sure they are installed.
library(here) #for data loading/saving
library(dplyr)
library(skimr)
library(ggplot2)
library(maps)
library(gt)
```


Load the data.

```{r}
#Path to data. Note the use of the here() package and not absolute paths
data_location <- here::here("data","processed-data","processeddata_cancer.rds")
#load data
mydata <- readRDS(data_location)
```

# bar chart for crude prevalence according to states

```{r}
# Group by state and calculate the total population and cancer cases
state_total <- mydata %>%
  group_by(StateDesc) %>%
  summarize(TotalPopulation = sum(PopulationCount),
            TotalCancerCases = sum(Cancer_Case))

# Calculate the prevalence for each state
state_total <- state_total %>%
  mutate(TotalPrevalence = TotalCancerCases / TotalPopulation)

# View the resulting dataframe
print(state_total)

# Load the map data for the US states
us_states <- map_data("state")
print(us_states)

# Convert StateDesc column to lowercase
state_total$StateDesc <- tolower(state_total$StateDesc)

# Merge the map data with the state_totals dataframe
map_data <- merge(us_states, state_total, by.x = "region", by.y = "StateDesc", all.x = TRUE)

# Plot the map
map <- ggplot() +
  geom_map(data = map_data, map = map_data,
           aes(x = long, y = lat, map_id = region, fill = TotalPrevalence),
           color = "black", size = 0.1) +
  scale_fill_gradient(name = "TotalPrevalence", low = "lightblue", high = "darkblue") +
  labs(title = "Cancer Prevalence by State") +
  theme_void() +
  theme(legend.position = "right")
plot(map)
```

# List 10 cities that has the highest cancer prevalence

```{r}
top_10_highest <- mydata %>%
  top_n(10, Data_Value) %>%
  select(Year, StateAbbr, CityName, Data_Value)

print(top_10_highest)

# create a table
table <- top_10_highest %>%
  gt() %>%
  tab_spanner(
    label = md('**Year**'),
    columns = c('Year')
  ) %>%
  tab_spanner(
    label = md('**State**'),
    columns = c('StateAbbr')
  ) %>%
  tab_spanner(
    label =  md('**Cancer Prevalence**'),
    columns = c('Data_Value')
  ) %>%
  tab_header(
    title = '2017 top 10 cities which have highest cancer rates'
  ) %>%
  opt_stylize(style = 6, color = 'gray')
```

We are saving the results to the `results` folder. Depending on how many tables/figures you have, it might make sense to have separate folders for each. And/or you could have separate folders for exploratory tables/figures and for final tables/figures. Just choose a setup that makes sense for your project and works for you, and provide enough documentation that someone can understand what you are doing.

# fit a simple linear model

```{r}
# create boxplot of Fare by Passenger class
bp1 <- ggplot(mydata, aes(x = as.factor(Pclass), y = Fare)) +
  geom_boxplot() +
  labs(title = "Boxplot of Ticket Fare by Passenger Class",
       x = "Passenger Class",
       y = "Fare") +
  theme_minimal()
plot(bp1)
figure_file = here("results","figures", "seed_type.png")
ggsave(filename = figure_file, plot=bp1) 
```

Then goes strain type: box plot

```{r}
# Create boxplot for bacterial population by 
bp2 <- ggplot(mydata, aes(x = Strain, y = Selective)) +
  geom_boxplot() +
  labs(title = "The population difference by treatment",
       x = "Strain type",
       y = "Average Population") +
  theme_minimal()
plot(bp2)
figure_file = here("results","figures", "strain_type.png")
ggsave(filename = figure_file, plot=bp2) 
```

Now the effect of the treatment: bar chart with color gradient as an indicator

```{r}
# Calculate average population by seed type
mydata_treatment <- mydata %>%
  group_by(Treatment) %>%
  summarize(mean_Selective = mean(Selective),
            sd_Selective = sd(Selective))

# Create a continuous variable for fill
mydata_treatment$fill_color <- scales::rescale(mydata_treatment$mean_Selective)

# Create the bar chart with standard deviation lines
bp3 <- ggplot(mydata_treatment, aes(x = Treatment, y = mean_Selective, fill = fill_color)) +
  geom_bar(stat = "identity", position = "dodge", alpha = 0.7, width = 0.4)  +
  geom_errorbar(data = mydata_treatment, aes(x = Treatment, ymin = mean_Selective - sd_Selective, ymax = mean_Selective + sd_Selective, color = "grey"),
                position = position_dodge(width = 0.1), width = 0.05) +
  labs(title = "The population difference by treatment",
       x = "Treatment",
       y = "Average Population") +
  scale_fill_gradient(low = "yellow", high = "red") +  # Adjust the colors as needed
  scale_color_manual(values = c("grey")) +  # Use grey color for error bar color
  guides(color = "none") +  # Turn off both fill and color legends
  theme_minimal()
plot(bp3)
figure_file = here("results","figures", "treatment.png")
ggsave(filename = figure_file, plot=bp3) 
```


The growth trend of the bacterial population over time: scatterplot with line

```{r}
# Calculate the average population for each day
mydata_day <- aggregate(Selective ~ Day, data = mydata, FUN = mean)

# Draw a point plot
sp4 <- ggplot(mydata_day, aes(x = Day, y = Selective)) +
  geom_point(size = 2, color = "blue") +
  geom_line(aes(group = 1), color = "red") +
  labs(title = "The growth trend of the bacterial population over time",
       x = "Day",
       y = "Average Bacterial Population") +
  theme_minimal()
plot(sp4)
figure_file = here("results","figures", "timepoint.png")
ggsave(filename = figure_file, plot=sp4) 
```
```

# Notes

For your own explorations, tables and figures can be "quick and dirty". As long as you can see what's going on, there is no need to polish them. That's in contrast to figures you'll produce for your final products (paper, report, presentation, website, etc.). Those should look as nice, polished and easy to understand as possible.


